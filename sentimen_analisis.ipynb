{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1: INSTALL & IMPORT\n",
    "# ==========================================\n",
    "!pip install pandas textblob plotly wordcloud matplotlib requests nltk\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download database kata sambung (stopwords)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: LOAD DATA, PREPROCESSING & ANALYSIS\n",
    "import os\n",
    "\n",
    "if 'df' in locals(): del df\n",
    "\n",
    "# === KONFIGURASI SUMBER DATA ===\n",
    "# Ganti dengan path lokal atau URL kamu\n",
    "# source_path = \"data/yt_comment_ferry.json\" \n",
    "source_path = \"https://github.com/rhnrafif/datamining_1/blob/main/data/yt_comment_ferry.json\" \n",
    "\n",
    "def get_raw_url(github_url):\n",
    "    if 'github.com' in github_url and '/blob/' in github_url:\n",
    "        return github_url.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')\n",
    "    return github_url\n",
    "\n",
    "# --- 1. SETUP STOPWORDS (KATA YANG DIHAPUS) ---\n",
    "# Kita gabungkan stopwords resmi bahasa indonesia dengan bahasa gaul/slang\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "custom_slang = {\n",
    "    'yg', 'gak', 'ga', 'kalo', 'kl', 'bgt', 'dr', 'dlm', 'tdk', 'jd', \n",
    "    'jgn', 'sdh', 'aja', 'n', 't', 'ny', 'sy', 'aku', 'saya', 'kamu', \n",
    "    'dia', 'ini', 'itu', 'dan', 'di', 'ke', 'dari', 'yang', 'pada',\n",
    "    'untuk', 'bang', 'kak', 'min', 'gan', 'sis', 'bro', 'video', 'nya',\n",
    "    'dong', 'sih', 'kok', 'deh', 'mah', 'kan', 'ada', 'apa', 'tuh', 'gw'\n",
    "}\n",
    "stop_words = stop_words.union(custom_slang)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()               # 1. Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)    # 2. Hapus tanda baca/emoji\n",
    "    text = re.sub(r'\\d+', '', text)        # 3. Hapus angka (opsional)\n",
    "    \n",
    "    # 4. Hapus Stopwords\n",
    "    words = text.split()\n",
    "    cleaned_words = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "\n",
    "try:\n",
    "    print(f\"Memeriksa sumber data: {source_path}\")\n",
    "    text_data = \"\"\n",
    "\n",
    "    # --- LOAD DATA LOGIC (URL vs LOCAL) ---\n",
    "    if source_path.startswith('http'):\n",
    "        print(\"Terdeteksi sebagai URL. Mengunduh data...\")\n",
    "        raw_url = get_raw_url(source_path)\n",
    "        response = requests.get(raw_url)\n",
    "        if response.status_code != 200: raise Exception(f\"Gagal download! Status: {response.status_code}\")\n",
    "        text_data = response.text\n",
    "    else:\n",
    "        print(\"Terdeteksi sebagai File Lokal. Membuka file...\")\n",
    "        if not os.path.exists(source_path):\n",
    "            # Auto-search path\n",
    "            for root, dirs, files in os.walk(\".\"):\n",
    "                if os.path.basename(source_path) in files:\n",
    "                    source_path = os.path.join(root, os.path.basename(source_path))\n",
    "                    break\n",
    "        with open(source_path, 'r', encoding='utf-8') as f:\n",
    "            text_data = f.read()\n",
    "\n",
    "    # --- PARSING JSON ---\n",
    "    text_data_fixed = re.sub(r',\\s*]', ']', text_data)\n",
    "    text_data_fixed = re.sub(r',\\s*}', '}', text_data_fixed)\n",
    "    \n",
    "    json_data = json.loads(text_data_fixed)\n",
    "    df = pd.DataFrame(json_data)\n",
    "    print(f\"Data Valid! Berhasil memuat {len(df)} baris.\")\n",
    "\n",
    "    # --- PREPROCESSING (NEW!) ---\n",
    "    print(\"Melakukan pembersihan teks (Cleaning)...\")\n",
    "    # Kita simpan teks bersih di kolom baru 'text_clean'\n",
    "    df['text_clean'] = df['text'].apply(clean_text)\n",
    "\n",
    "    # --- ANALISIS SENTIMEN ---\n",
    "    print(\"Menjalankan analisis sentimen...\")\n",
    "    # Kita analisis kolom asli 'text' agar konteks emosi tetap dapat (TextBlob butuh struktur kalimat)\n",
    "    # Tapi nanti WordCloud pakai 'text_clean'\n",
    "    \n",
    "    def get_score(text):\n",
    "        try: return TextBlob(str(text)).sentiment.polarity\n",
    "        except: return 0\n",
    "        \n",
    "    def get_label(score):\n",
    "        if score > 0.05: return 'Positif'    # Ambang batas sedikit diturunkan\n",
    "        elif score < -0.05: return 'Negatif'\n",
    "        else: return 'Netral'\n",
    "\n",
    "    df['score'] = df['text'].apply(get_score)\n",
    "    df['label'] = df['score'].apply(get_label)\n",
    "    \n",
    "    # Format Tanggal\n",
    "    if 'published_at' in df.columns:\n",
    "        df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "        df['date_only'] = df['published_at'].dt.date\n",
    "    else:\n",
    "        df['date_only'] = pd.Timestamp.now().date()\n",
    "    \n",
    "    print(\"Selesai! Data bersih ada di kolom 'text_clean'.\")\n",
    "    print(df[['text', 'text_clean', 'label']].head()) # Preview bedanya\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELL 3: PIE CHART & BAR CHART\n",
    "\n",
    "if 'df' in locals():\n",
    "    # 1. Pie Chart Interaktif\n",
    "    fig_pie = px.pie(df, names='label', title='Proporsi Sentimen Komentar',\n",
    "                     color='label', \n",
    "                     color_discrete_map={'Positif':'#00CC96', 'Negatif':'#EF553B', 'Netral':'#AB63FA'},\n",
    "                     hole=0.4)\n",
    "    fig_pie.show()\n",
    "\n",
    "    # 2. Bar Chart (Top Videos)\n",
    "    if 'video_title' in df.columns:\n",
    "        video_counts = df.groupby(['video_title', 'label']).size().reset_index(name='jumlah')\n",
    "        # Ambil Top 5 Video saja\n",
    "        top_videos = df['video_title'].value_counts().nlargest(5).index\n",
    "        video_counts_filtered = video_counts[video_counts['video_title'].isin(top_videos)]\n",
    "\n",
    "        fig_bar = px.bar(video_counts_filtered, x=\"jumlah\", y=\"video_title\", color=\"label\",\n",
    "                         title=\"Sentimen pada 5 Video Terpopuler\", orientation='h',\n",
    "                         color_discrete_map={'Positif':'#00CC96', 'Negatif':'#EF553B', 'Netral':'#AB63FA'})\n",
    "        fig_bar.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataframe belum terbentuk. Cek Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: TIME SERIES (TREND)\n",
    "if 'df' in locals():\n",
    "    # Group by Date & Label\n",
    "    timeline = df.groupby(['date_only', 'label']).size().reset_index(name='count')\n",
    "    \n",
    "    fig_line = px.line(timeline, x='date_only', y='count', color='label',\n",
    "                       title='Tren Sentimen dari Waktu ke Waktu',\n",
    "                       markers=True,\n",
    "                       color_discrete_map={'Positif':'#00CC96', 'Negatif':'#EF553B', 'Netral':'#AB63FA'})\n",
    "    \n",
    "    fig_line.update_xaxes(title_text='Tanggal')\n",
    "    fig_line.update_yaxes(title_text='Jumlah Komentar')\n",
    "    fig_line.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: SCATTER PLOT (LIKES VS SENTIMENT)\n",
    "if 'df' in locals() and 'likes' in df.columns:\n",
    "    fig_scat = px.scatter(df, x=\"score\", y=\"likes\", \n",
    "                          color=\"label\", size=\"likes\", \n",
    "                          hover_data=['text', 'author'], # Fitur keren: hover mouse untuk baca!\n",
    "                          title=\"Hubungan Skor Sentimen vs Jumlah Likes\",\n",
    "                          color_discrete_map={'Positif':'#00CC96', 'Negatif':'#EF553B', 'Netral':'#AB63FA'})\n",
    "    \n",
    "    fig_scat.update_layout(xaxis_title=\"Skor Sentimen (-1 Negatif s.d 1 Positif)\", yaxis_title=\"Jumlah Likes\")\n",
    "    fig_scat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25631203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: WORD CLOUD (BERSIH)\n",
    "if 'df' in locals():\n",
    "    print(\"‚è≥ Generating WordCloud dari teks bersih...\")\n",
    "    \n",
    "    # Gabungkan teks dari kolom 'text_clean'\n",
    "    text_combined = \" \".join(df['text_clean'].astype(str).tolist())\n",
    "    \n",
    "    if len(text_combined) > 0:\n",
    "        wordcloud = WordCloud(width=800, height=400, \n",
    "                              background_color='white', \n",
    "                              colormap='viridis',\n",
    "                              min_font_size=10).generate(text_combined)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Word Cloud: Topik Pembicaraan Utama\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Bonus: Tampilkan Komentar Paling Ekstrem\n",
    "        print(\"\\nüîç KOMENTAR PALING POSITIF:\")\n",
    "        display(df.sort_values(by='score', ascending=False).head(3)[['author', 'text', 'score']])\n",
    "        \n",
    "        print(\"\\nüîç KOMENTAR PALING NEGATIF:\")\n",
    "        display(df.sort_values(by='score', ascending=True).head(3)[['author', 'text', 'score']])\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Data teks kosong setelah dibersihkan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
