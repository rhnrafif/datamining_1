{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. INSTALASI & IMPORT\n",
    "print(\"Menginstall library NLP & Plotting...\")\n",
    "!pip install -q Sastrawi pandas scikit-learn matplotlib seaborn nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. DOWNLOAD DATA (AUTO RAW URL)\n",
    "# Link asli dari kamu (masih format blob/html)\n",
    "original_url = \"https://github.com/rhnrafif/datamining_1/blob/main/data/dataset_pidato_UN.csv\"\n",
    "\n",
    "# Ubah otomatis ke format RAW agar bisa didownload mesin\n",
    "raw_url = original_url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "\n",
    "print(f\"Mendownload pidato dari: {raw_url}\")\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# Download pakai wget biar stabil\n",
    "!wget -q -O data/pidato_prabowo.csv {raw_url}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaa6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. LOAD & CHUNK (MEMECAH PIDATO)\n",
    "print(\"Memproses & Memecah Pidato...\")\n",
    "\n",
    "# Baca file sebagai text biasa (bukan CSV kolom) karena isinya pidato panjang\n",
    "try:\n",
    "    with open('data/pidato_prabowo.csv', 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "except:\n",
    "    # Fallback encoding lain jika utf-8 gagal\n",
    "    with open('data/pidato_prabowo.csv', 'r', encoding='latin-1') as f:\n",
    "        full_text = f.read()\n",
    "\n",
    "# FUNGSI PEMECAH PARAGRAF\n",
    "def split_paragraphs(text):\n",
    "    # Bersihkan artifact CSV (tanda kutip ganda berlebih)\n",
    "    text = text.replace('\"\"\"', '').replace('\"\"', '')\n",
    "    \n",
    "    # Pecah berdasarkan Baris Baru (Enter)\n",
    "    parts = text.split('\\n')\n",
    "    \n",
    "    clean_parts = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        # Ambil paragraf yang bermakna (lebih dari 50 huruf)\n",
    "        # Biar judul pendek/salam pembuka ga jadi noise\n",
    "        if len(p) > 30: \n",
    "            clean_parts.append(p)\n",
    "    return clean_parts\n",
    "\n",
    "paragraphs = split_paragraphs(full_text)\n",
    "df = pd.DataFrame(paragraphs, columns=['text_original'])\n",
    "\n",
    "print(f\"Pidato berhasil dipecah menjadi: {len(df)} Paragraf/Bagian.\")\n",
    "print(\"Contoh data awal:\")\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. PREPROCESSING (SASTRAWI)\n",
    "print(\"\\nüßπ Membersihkan teks (Stopwords & Stemming)...\")\n",
    "\n",
    "factory_stop = StopWordRemoverFactory()\n",
    "stopword = factory_stop.create_stop_word_remover()\n",
    "factory_stem = StemmerFactory()\n",
    "stemmer = factory_stem.create_stemmer()\n",
    "\n",
    "# Tambahan stopwords khusus pidato (biar ga muncul di cluster)\n",
    "custom_ignore = ['yang', 'mulia', 'para', 'hadirin', 'sekalian', 'tuan', 'pbb', 'presiden', 'di', 'dan', 'ke', 'dari']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+', '', text) # Hapus angka\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # Hapus simbol\n",
    "    \n",
    "    # Hapus stopwords bawaan\n",
    "    text = stopword.remove(text)\n",
    "    \n",
    "    # Hapus stopwords custom\n",
    "    for word in custom_ignore:\n",
    "        text = text.replace(f\" {word} \", \" \")\n",
    "    \n",
    "    # Stemming (Cukup lama, sabar ya)\n",
    "    text = stemmer.stem(text)\n",
    "    return text\n",
    "\n",
    "# Terapkan ke semua paragraf\n",
    "df['text_clean'] = df['text_original'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b73835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. TF-IDF & K-MEANS\n",
    "print(\"Menghitung K-Means...\")\n",
    "\n",
    "# Ubah huruf jadi angka\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text_clean'])\n",
    "\n",
    "# KITA BAGI JADI 3 TOPIK UTAMA (Misal: Pembukaan/Diplomasi, Sejarah/Kolonialisme, Tantangan Masa Depan)\n",
    "JUMLAH_CLUSTER = 3 \n",
    "\n",
    "kmeans = KMeans(n_clusters=JUMLAH_CLUSTER, random_state=42)\n",
    "kmeans.fit(X)\n",
    "df['cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. VISUALISASI HASIL (SCATTER PLOT)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"PETA TOPIK PIDATO\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Gunakan PCA untuk bikin koordinat X dan Y\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x=coords[:,0], \n",
    "    y=coords[:,1], \n",
    "    hue=df['cluster'], \n",
    "    palette='viridis', \n",
    "    s=100,\n",
    "    style=df['cluster']\n",
    ")\n",
    "\n",
    "plt.title(f'Sebaran Topik Pidato Presiden (K={JUMLAH_CLUSTER})')\n",
    "plt.xlabel('Dimensi Topik 1')\n",
    "plt.ylabel('Dimensi Topik 2')\n",
    "plt.legend(title='Kelompok Topik')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. INTERPRETASI (APA ISI CLUSTERNYA?)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"BEDAH ISI PIDATO PER KELOMPOK\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Fungsi cari kata kunci per cluster\n",
    "def get_top_keywords(data, clusters, labels, n_terms=5):\n",
    "    df_temp = pd.DataFrame(data.todense()).groupby(clusters).mean()\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    for i, r in df_temp.iterrows():\n",
    "        print(f\"\\nüìÇ KELOMPOK {i}:\")\n",
    "        print(f\"   (Kata Kunci Dominan: {', '.join([terms[t] for t in np.argsort(r)[-n_terms:]])})\")\n",
    "        print(\"-\" * 20)\n",
    "        # Tampilkan contoh kalimat asli\n",
    "        contoh = df[df['cluster'] == i]['text_original'].head(2).tolist()\n",
    "        for c in contoh:\n",
    "            print(f\"   üó£Ô∏è \\\"{c[:100]}...\\\"\")\n",
    "\n",
    "get_top_keywords(X, df['cluster'], kmeans.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
