{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. INSTALASI & IMPORT\n",
    "print(\"Menginstall library WordCloud & lainnya...\")\n",
    "!pip install -q Sastrawi pandas scikit-learn matplotlib seaborn nltk wordcloud requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. DOWNLOAD DATA (Python Native)\n",
    "# Link asli (Dataset Pidato UN)\n",
    "original_url = \"https://github.com/rhnrafif/datamining_1/blob/main/data/dataset_pidato_UN.csv\"\n",
    "raw_url = original_url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "\n",
    "print(f\"Mendownload pidato...\")\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "try:\n",
    "    response = requests.get(raw_url)\n",
    "    with open('data/pidato_prabowo.csv', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Baca konten file\n",
    "    with open('data/pidato_prabowo.csv', 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "    print(\"Download Berhasil!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gagal download (Coba cek koneksi): {e}\")\n",
    "    full_text = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9356b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. CHUNKING & PREPROCESSING\n",
    "print(\"Memproses teks...\")\n",
    "\n",
    "def split_paragraphs(text):\n",
    "    text = text.replace('\"\"\"', '').replace('\"\"', '')\n",
    "    parts = text.split('\\n')\n",
    "    clean_parts = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if len(p) > 30: # Ambil paragraf > 30 huruf\n",
    "            clean_parts.append(p)\n",
    "    return clean_parts\n",
    "\n",
    "df = pd.DataFrame(split_paragraphs(full_text), columns=['text_original'])\n",
    "\n",
    "# Setup Sastrawi\n",
    "factory_stop = StopWordRemoverFactory()\n",
    "stopword = factory_stop.create_stop_word_remover()\n",
    "factory_stem = StemmerFactory()\n",
    "stemmer = factory_stem.create_stemmer()\n",
    "\n",
    "# Stopwords tambahan agar WordCloud bersih\n",
    "custom_ignore = ['yang', 'mulia', 'para', 'hadirin', 'sekalian', 'tuan', 'pbb', 'presiden', 'di', 'dan', 'ke', 'dari', 'itu', 'ini', 'adalah', 'kami', 'kita', 'saya']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = stopword.remove(text)\n",
    "    for word in custom_ignore: # Hapus kata umum\n",
    "        text = text.replace(f\" {word} \", \" \")\n",
    "    text = stemmer.stem(text)\n",
    "    return text\n",
    "\n",
    "df['text_clean'] = df['text_original'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa999fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. K-MEANS CLUSTERING\n",
    "print(\"Menghitung Cluster...\")\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text_clean'])\n",
    "\n",
    "JUMLAH_CLUSTER = 3\n",
    "kmeans = KMeans(n_clusters=JUMLAH_CLUSTER, random_state=42)\n",
    "kmeans.fit(X)\n",
    "df['cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e477d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. VISUALISASI SCATTER PLOT\n",
    "print(\"Membuat Grafik Sebaran...\")\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=coords[:,0], y=coords[:,1], hue=df['cluster'], palette='viridis', s=100, style=df['cluster'])\n",
    "plt.title(f'Peta Topik Pidato ({JUMLAH_CLUSTER} Cluster)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. VISUALISASI WORD CLOUD\n",
    "print(\"WORD CLOUD PER TOPIK\")\n",
    "\n",
    "# Loop untuk setiap cluster\n",
    "for i in range(JUMLAH_CLUSTER):\n",
    "    print(f\"\\nüìÇ KELOMPOK TOPIK {i}:\")\n",
    "    \n",
    "    # Gabungkan semua teks dalam cluster ini menjadi satu string raksasa\n",
    "    subset = df[df['cluster'] == i]\n",
    "    text_gabungan = \" \".join(subset['text_clean'])\n",
    "    \n",
    "    if len(text_gabungan) > 0:\n",
    "        # Bikin Word Cloud\n",
    "        wc = WordCloud(\n",
    "            background_color='white',\n",
    "            width=800, \n",
    "            height=400,\n",
    "            colormap='Dark2', # Warna teks\n",
    "            stopwords=custom_ignore\n",
    "        ).generate(text_gabungan)\n",
    "        \n",
    "        # Tampilkan Gambar\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis(\"off\") # Hilangkan sumbu X/Y\n",
    "        plt.title(f\"Kata Kunci Dominan - Kelompok {i}\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Tampilkan contoh kalimat asli biar user paham konteksnya\n",
    "        print(\"   üó£Ô∏è Contoh Kalimat Asli:\")\n",
    "        print(f\"   - \\\"{subset['text_original'].iloc[0][:150]}...\\\"\")\n",
    "    else:\n",
    "        print(\"   (Data terlalu sedikit untuk membuat Word Cloud)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
